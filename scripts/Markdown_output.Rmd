---
title: "Class Exercise 2"
author: "Bernhard, Josia, Nico"
date: "`r Sys.Date()`"
output: html_document
---
# Number of Articles in the Guardian on COVID-19 and the Russian Invasion of Ukraine

This is the Class exercise 2 of Bernhard, Nico and Josia for the Data Mining in R class of spring 2024.

## Introduction
Since our attention became the product of many companies, companies started competing for it. The news industry is not freed of this competition, because the decline of subscription-based business models has lead to a rise of advertisement-based business models, which are dependent on the quantity of clicks. The more serious newspapers find themselves in a double and potentially conflicting role, with The Guardian having the mission statement: "to use clarity and imagination to build hope", but also having to compete for attention, with research proving that negativity drives online news consumption (Robertson et al., 2023).
The research objective of this class exercise is to analyze on whether The Guardian articles published on COVID-19 reduced dramatically with the Russian invasion of Ukraine, which might imply that The Guardian jumped from one crisis to the next one.


## Methods
We used the Guardian API to extract the number of articles published per week on the topics of COVID-19 and the Russian invasion of Ukraine. The time period stretches from the 8th of January 2021 to the 12th of April 2024. We will then compare the number of articles published on these topics over time. To model the severity of COVID-19 in the UK, and whether it correlates with the number of articles published on the topic, we added the weekly deaths in the UK due to COVID-19 to the analysis, which we extracted from the UK National Health Security Agency (NHS) API.

## Hypothesis
The decline of articles on the topic of COVID-19 goes along with a rise in articles on the topic of the russian invasion on Ukraine and with a decline of deaths of COVID-19 in the UK.


### Load libraries, clear workspace

```{r setup, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
rm(list = ls())

library(httr)
library(jsonlite)
library(lubridate)
library(tidyverse)
library(knitr)


# change the wd to one hierarchy higher because for some reason it was in scripts for the .rmd file
opts_knit$set(root.dir = normalizePath(".."))

```

### The Guardian data extraction




```{r}

if(!file.exists("data/article_counts_covid.RData")) {

  
  
# load api key and base_url, set to search to find content
api_key <- rstudioapi::askForPassword("Enter Guardian API Key")
base_url <- "https://content.guardianapis.com/search"

# define the start and end date, both are chosen as a monday
start_date <- as.Date("2021-01-01")
end_date <- as.Date("2024-04-05")


# test whether we can get every start and end date of each week for the for loop later
week_dates <- seq(from = start_date, to = end_date, by = "week")

for(week_start in week_dates) {
  print(as.Date(week_start))
  
  end_date = week_start +7
  print(as.Date(end_date))
  cat("\n")
}


# init df to store covid results
results_covid <- data.frame(WeekStart = as.Date(character()), TotalArticles = integer())

# Loop over each week
for (week_start in week_dates) {


  week_end = week_start + 7
  
  # Set up API parameters for the current week
  params <- list(
    'api-key' = api_key,
    'q' = "COVID-19 OR coronavirus",
    'from-date' = as.character(as.Date(week_start)),
    'to-date' = as.character(as.Date(week_end))
  )
  
  # Perform the API call
  response <- GET(base_url, query = params)
  if (status_code(response) == 200) {
    content <- content(response, "text")
    json <- fromJSON(content)
    total_articles <- json$response$total
    
    # Append the results to the dataframe
    results_covid <- rbind(results_covid, data.frame(WeekStart = as.Date(week_end), TotalArticles = total_articles))
    
    # Debug output
    print(paste("Week starting:", as.Date(week_start), "- Total Articles:", total_articles))
  } else {
    print(paste("Failed to retrieve data for week starting:", as.Date(week_start)))
    
    
  }
  
  Sys.sleep(abs(rnorm(n = 1, mean = 1.5, sd = 0.4)))
}  


save(results_covid, file = "data/article_counts_covid.RData")

} else {
load(file = "data/article_counts_covid.RData")
}


if(!file.exists("data/article_counts_russia.RData")) {


# init df to store russian/ukraine results
results_russia <- data.frame(WeekStart = as.Date(character()), TotalArticles = integer())

# Loop over each week
for (week_start in week_dates) {
  
  
  week_end = week_start + 7
  
  # Set up API parameters for the current week
  params <- list(
    'api-key' = api_key,
    'q' = "Russia OR Ukraine",
    'from-date' = as.character(as.Date(week_start)),
    'to-date' = as.character(as.Date(week_end))
  )
  
  # Perform the API call
  response <- GET(base_url, query = params)
  if (status_code(response) == 200) {
    content <- content(response, "text")
    json <- fromJSON(content)
    total_articles <- json$response$total
    
    # Append the results to the dataframe
    results_russia <- rbind(results_russia, data.frame(WeekStart = as.Date(week_end), TotalArticles = total_articles))
    
    # Debug output
    print(paste("Week starting:", as.Date(week_end), "- Total Articles:", total_articles))
  } else {
    print(paste("Failed to retrieve data for week starting:", as.Date(week_end)))
    
    
  }
  
  Sys.sleep(abs(rnorm(n = 1, mean = 1.5, sd = 0.4)))
}  

save(results_russia, file = "data/article_counts_russia.RData")

} else {
  load(file = "data/article_counts_russia.RData")
}


summary(results_covid)
summary(results_russia)

```

## NHS data extraction

```{r}

if(!file.exists("data/UK_weekly_covid_death.RData")) {

url <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics"

response <- GET(url)
content <- content(response, "text")
json_overview <- fromJSON(content)




# try: COVID-19_cases_rateRollingMean -------------------------------------

url <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_cases_rateRollingMean"

response <- GET(url)
content <- content(response, "text")
json <- fromJSON(content)

# this gives us just one datapoint, lets add filters at the end to get more


# try to get the weekly deaths for 365 pages ------------------------------

url <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_deaths_ONSRegByWeek?page_size=365"

response <- GET(url)
content <- content(response, "text")
json <- fromJSON(content)

# this gives us the covid-19 deaths, but for some reason the data starts in 2021

# lets try the positivity rate, it is weekly aswell -----------------------

url <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_cases_lineagePercentByWeek?page_size=365"
response <- GET(url)
content <- content(response, "text")
json <- fromJSON(content)

# this variables is actually the percentage of the prevalent variants of covid-19, not the positivity rate of tests


# lets go back to the deaths and try to get the ones from 2020 ------------


url <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_deaths_ONSRegByWeek?year=2020"

response <- GET(url)
content <- content(response, "text")
json <- fromJSON(content)



# to add more filters, we use the params list -----------------------------

base_url_deaths <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_deaths_ONSRegByWeek"

q_params <- list(
  page_size = 365,
  year = 2020
)

response <- GET(base_url_deaths, query = q_params)
content <- content(response, "text")
json <- fromJSON(content)

# if i include the year it returns an empty list, maybe they dont have it, or im doing some mistake


# get the weekly death starting in 2021 -----------------------------------

base_url_deaths <- "https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_deaths_ONSRegByWeek"

q_params <- list(
  page_size = 365
)

response <- GET(base_url_deaths, query = q_params)
content <- content(response, "text")
json <- fromJSON(content)

# clean the data, extract the counts and dates ----------------------------

class(json$results)

UK_weekly_death <- json$results

names(UK_weekly_death)
View(UK_weekly_death)

UK_weekly_death <- UK_weekly_death %>% 
  select(date, metric_value) %>% 
  rename(COVID_deaths_UK = metric_value) %>% 
  mutate(date = as.Date(date)) %>% 
  rename(WeekStart = date)

sapply(UK_weekly_death, class)


save(UK_weekly_death, file = "data/UK_weekly_covid_death.RData")


} else {
    load(file = "data/UK_weekly_covid_death.RData")
}

summary(UK_weekly_death)
```

## Data Cleaning and Plots

```{r}

results_covid_renamed <- results_covid %>% 
  rename(Articles_covid19 = TotalArticles)

results_russia_renamed <- results_russia %>% 
  rename(Articles_ukraine_russia = TotalArticles)

df_combined <- left_join(results_covid_renamed, results_russia_renamed, by = "WeekStart")
df_comb_covid <- left_join(results_covid_renamed, UK_weekly_death, by = "WeekStart")


df_long <- df_combined %>%
  pivot_longer(cols = c(Articles_ukraine_russia, Articles_covid19),
               names_to = "Variable",
               values_to = "Count")

  

df_long_covid <- df_comb_covid %>%
  pivot_longer(cols = c(Articles_covid19, COVID_deaths_UK),
               names_to = "Variable",
               values_to = "Count")


p1 <-ggplot(data = df_long, aes(x = WeekStart, y = Count, color = Variable)) +
  geom_line() +
  labs(title = "The Guardian Weekly Articles Published \non Ukraine/Russia and COVID-19", x = "Monthly Data", y = "Count", color = "Variable") +
  scale_color_manual(values = c("Articles_ukraine_russia" = "blue", "Articles_covid19" = "red")) +
  theme_minimal()

ggsave(p1,
       filename = here::here("output", "articles.png"),
       device = "png",
       width = 6, height = 4, units = "in",
       dpi = 600)

p2 <- ggplot(data = df_long_covid, aes(x = WeekStart, y = Count, color = Variable)) +
  geom_line() +
  labs(title = "The Guardian Weekly Articles Published \non COVID-19 and Weekly UK COVID-19 Deaths", x = "Monthly Data", y = "Count", color = "Variable") +
  scale_color_manual(values = c("COVID_deaths_UK" = "blue", "Articles_covid19" = "red")) +
  theme_minimal()

ggsave(p2,
       filename = here::here("output", "covid.png"),
       device = "png",
       width = 6, height = 4, units = "in",
       dpi = 600)


# Since the COVID-19 deaths and COVID-19 articles have different units, we scale and center the variables for plotting


df_comb_covid_scaled <- df_comb_covid %>% 
  mutate(Articles_covid19 = scale(as.numeric(Articles_covid19))) %>% 
  mutate(COVID_deaths_UK = scale(as.numeric(COVID_deaths_UK)))


df_long_covid_scaled <- df_comb_covid_scaled %>%
  pivot_longer(cols = c(Articles_covid19, COVID_deaths_UK),
               names_to = "Variable",
               values_to = "Count")



p3 <- ggplot(data = df_long_covid_scaled, aes(x = WeekStart, y = Count, color = Variable)) +
  geom_line() +
  labs(title = "The Guardian Weekly Articles Published \non COVID-19 and Weekly UK COVID-19 Deaths Standardized", x = "Monthly Data", y = "Standardized Count", color = "Variable") +
  scale_color_manual(values = c("COVID_deaths_UK" = "blue", "Articles_covid19" = "red")) +
  theme_minimal()

ggsave(p3,
       filename = here::here("output", "covid_scaled.png"),
       device = "png",
       width = 6, height = 4, units = "in",
       dpi = 600)

p1
p2
p3

```


## Results and Discussion
 
The data shows that the number of articles published on the topics of COVID-19 and the Russian invasion of Ukraine have been fluctuating over time. The number of articles published on COVID-19 has been decreasing over time, while the number of articles published on the Russian invasion of Ukraine spiked at the invasion and has been tapering off ever since. The weekly UK COVID-19 deaths were very large at the start of the collecting period, and has decreased since then. 

Interestingly, there is an overlap between the increase in the number of articles published on the Russian invasion of Ukraine and the decrease in the number of articles published on COVID-19 in the first half of 2022. This suggests that the number of articles published on COVID-19 might be negatively correlated with the number of articles published in the Russian invasion of Ukraine.

Furthermore, there is an overlap between the decrease in the number of articles published on COVID-19 and the decrease in the number of weekly deaths in the UK due to COVID-19. This suggests that the decrease in the number of articles published on COVID-19 may be related to the decrease in the number of weekly deaths in the UK due to COVID-19.

Limitations
We could not manage to do statistical testing on our time series data. Therefore, we cannot formally reject the null hypothesis, which would be no correlation between the number of COVID-19 articles and the number of articles on the Russion invasion of Ukraine.

## Conclusion

Overall, the data suggests that the number of articles published on COVID-19 and the Russian invasion of Ukraine may be related to each other and to the number of weekly deaths in the UK due to COVID-19. Further analysis is needed to determine the exact nature of these relationships.



